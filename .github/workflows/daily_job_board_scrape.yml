name: Daily Python Script

on:
  schedule:
    - cron: "0 7 * * *"
  push:
    branches:
      - main

env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_REGION: ${{ secrets.AWS_REGION }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  HASHIDS_SALT: ${{ secrets.HASHIDS_SALT }}
  PAGES_TO_SCRAPE_QUERY: ${{ secrets.PAGES_TO_SCRAPE_QUERY }}
  PG_DATABASE: ${{ secrets.PG_DATABASE }}
  PG_HOST: ${{ secrets.PG_HOST }}
  PG_PASSWORD: ${{ secrets.PG_PASSWORD }}
  PG_USER: ${{ secrets.PG_USER }}
  RAW_HTML_S3_BUCKET: ${{ secrets.RAW_HTML_S3_BUCKET }}
  COMPARISON_QUERY_EXPECTED: ${{ secrets.COMPARISON_QUERY_EXPECTED }}
  COMPARISON_QUERY_ACTUAL: ${{ secrets.COMPARISON_QUERY_ACTUAL }}
  MISMATCHED_URL_QUERY: ${{ secrets.MISMATCHED_URL_QUERY }}

jobs:
  run_script:
    name: Call Scrapy Script
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Obtain IP Address
        run: |
          echo "MY_IP=$(curl https://api.ipify.org)" >> $GITHUB_ENV
          echo $MY_IP
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/Github-Actions-Role
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Whitelist this IP
        run: |
          aws ec2 authorize-security-group-ingress \
          --group-id ${{ secrets.AWS_PG_SECURITY_GROUP }} \
          --protocol tcp \
          --port 5432 \
          --cidr ${{ env.MY_IP }}/32
      
      - name: Obtain Time Before Scrapy Run
        run : echo "CURRENT_TIME=$(date +%s)" >> $GITHUB_ENV
      
      - name: Run Scrapy script
        run: cd job_board_scraper && python run_job_scraper.py 

      - name: Confirm Scrapy Worked for Each Company
        run: cd job_board_scraper && python compare_workflow_success.py ${{ env.CURRENT_TIME }}
  
      - name: Deauthorize IP
        if: ${{ always() }}
        run: |
          aws ec2 revoke-security-group-ingress \
          --group-id ${{ secrets.AWS_PG_SECURITY_GROUP }} \
          --protocol tcp \
          --port 5432 \
          --cidr ${{ env.MY_IP }}/32
      


