version: 2

models:
  - name: stg_greenhouse__job_departments
    description: >
      Staging view of the job_departments source. Timestamps have been cast from Unix time. Deduping by levergreen id,
      only taking the earliest levergreen id. Meaning, each HTML source is only displayed once in this staging model.
    tests:
        - dbt_expectations.expect_table_columns_to_match_set:
            column_list: ["id", "levergreen_id", "created_at_utc", "updated_at_utc", 
            "created_date_utc", "updated_date_utc",
             "source", "company_name", "department_category", "department_id",
             "department_name", "uses_existing_html", "raw_html_file_location",
             "run_hash", "job_board"]
    columns:
      - name: id
        description: serial id created by postgres upon insertion.
      - name: levergreen_id
        description: Id from Levergreen scraper. Unique relative to the HTML file used.
      - name: created_at_utc
        description: Timestamp of when the greenhouse site was scraped, casted to UTC, timezone shown. If we used existing HTML, this field is not updated.
      - name: updated_at_utc
        description: Timestamp of when the greenhouse site was scraped, casted to UTC, timezone shown.
      - name: created_date_utc
        description: Date of when the greenhouse site was scraped, casted to UTC. 
      - name: updated_date_utc
        description: Date of when the greenhouse site was scraped, casted to UTC.
      - name: source
        description: Greenhouse careers page source. 
      - name: department_category
        description: Department Category. Specifies if deparmtent is main department or sub department.
      - name: department_id
        description: Greenhouse specific id for the department. Joins to Greenhouse Outline.
      - name: department_name
        description: Name of the Greenhouse Department
      - name: company_name
        description: Company name from Greenhouse. Taken by grabbing the end of the source.
      - name: raw_html_file_location
        description: S3 bucket where the scraped data is stored
      - name: uses_existing_html
        description: Boolean indicating whether the HTML from the scrape was taken from the website or from the s3 bucket.
      - name: run_hash
        description: Hashed value using hash ids to identify the id of a particular scraped
      - name: job_board
        description: Job board dervied from source
        tests:
          - accepted_values:
              values: ['greenhouse']

  - name: stg_greenhouse__jobs_outline
    description: >
      Staging view of the Greenhouse jobs_outline source. Timestamps have been cast from Unix time. Deduping by levergreen id,
      only taking the earliest levergreen id. Meaning, each HTML source is only displayed once in this staging model.
    tests:
      - dbt_expectations.expect_table_columns_to_match_set:
          column_list: ["id", "levergreen_id", "created_at_utc", "updated_at_utc",
           "created_date_utc", "updated_date_utc",
            "source", "department_ids", "location", "office_ids",
            "full_opening_link", "opening_title", "uses_existing_html",
            "raw_html_file_location", "run_hash", "job_board"]
    columns:
      - name: id
        description: serial id created by postgres upon insertion
      - name: levergreen_id
        description: Id from Levergreen scraper. Unique relative to the HTML file used
      - name: created_at_utc
        description: Timestamp of when the greenhouse site was scraped, in UNIX time. If we used existing HTML, this field is not updated.
      - name: updated_at_utc
        description: Timestamp of when the greenhouse site was scraped, in UNIX time.
      - name: created_date_utc
        description: Date of when the greenhouse site was scraped, casted to UTC. 
      - name: updated_date_utc
        description: Date of when the greenhouse site was scraped, casted to UTC.
      - name: source
        description: Greenhouse careers page source. 
      - name: department_ids
        description: Comma separated list of Greenhouse department_ids. Will use this to join to greenhouse_job_deparments further on in data models
      - name: office_ids
        description: Comma separated list of of office_ids. Sometimes null in the source data, not sure why
      - name: location
        description: Comma separated list of locations
      - name: full_opening_link
        description: Source of the actual job posting. Scraped value is only the suffix of the link, here we clean to have the full link.
      - name: opening_title
        description: Name of the role
      - name: raw_html_file_location
        description: S3 bucket where the scraped data is stored
      - name: uses_existing_html
        description: Boolean indicating whether the HTML from the scrape was taken from the website or from the s3 bucket.
      - name: run_hash
        description: Hashed value using hash ids to identify the id of a particular scraped
      - name: job_board
        description: Job board dervied from source
        tests:
          - accepted_values:
              values: ['greenhouse']
        